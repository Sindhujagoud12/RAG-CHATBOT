# My RAG Project

## Overview

A Retrievalâ€‘Augmented Generation (RAG) application that combines a **Streamlit** frontâ€‘end with a **FastAPI** backâ€‘end to provide intelligent, contextâ€‘aware answers over a custom document corpus.

## Features

- ğŸ“„ Load and index documents (PDF, TXT, Markdown) using **FAISS**.
- ğŸ¤– Query the indexed knowledge base with **OpenAI** (or any compatible LLM).
- ğŸ¨ Interactive UI built with **Streamlit** for realâ€‘time chat experience.
- âš¡ï¸ Simple Docker setup for reproducible local development.

## Quick Start

```bash
# Clone the repo
git clone https://github.com/Sindhujagoud12/RAG-CHATBOT.git
cd RAG-CHATBOT

# Create a virtual environment (optional but recommended)
python -m venv .venv
.\.venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Run the backend (FastAPI)
uvicorn rag_project_code:app --reload

# In a new terminal, run the Streamlit frontâ€‘end
streamlit run app.py
```

Open your browser at `http://localhost:8501` to start chatting with the RAG system.

## Project Structure

```
RAG-CHATBOT/
â”œâ”€ app.py            # Streamlit UI entry point
â”œâ”€ rag_project_code.py        # FastAPI server handling document loading & retrieval
â”œâ”€ requirements.txt  # Python dependencies
â”œâ”€ README.md         
```

## Configuration

- **LLM Provider** â€“ Set the `GROQ_API_KEY` environment variable or modify `rag_project_code.py` to use another provider.
- **Document Folder** â€“ Place your source files in the `docs/` directory; the rag_project_code.py will index them on startup.

## Contributing

Contributions are welcome! Please fork the repository, create a feature branch, and submit a pull request. Follow the existing code style and ensure all tests pass.

## License

This project is licensed under the MIT License â€“ see the [LICENSE](LICENSE) file for details.
